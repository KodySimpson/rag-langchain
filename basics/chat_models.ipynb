{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# load the environment variables\n",
    "%pip install -qU python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# loads the .env file (if you have a global environment variable, you can skip this)\n",
    "load_dotenv()\n",
    "\n",
    "# lets just validate that we have the environment variable\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the environment variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of models can be found here: https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"In the United States, the president's term lasts four years. A president may serve a maximum of two terms, for a total of eight years, as established by the 22nd Amendment to the Constitution.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 16, 'total_tokens': 59, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-37162f25-ca30-4b26-b73b-35f1988d915c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 43, 'total_tokens': 59, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "model.invoke(\"How long does the president's term last?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of the United States is Washington, D.C.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 16, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None}, id='run-341ae179-1233-41fe-86d7-98d999a96b64-0', usage_metadata={'input_tokens': 16, 'output_tokens': 13, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can provide more settings\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5, max_tokens=1000, top_p=0.95, frequency_penalty=0, presence_penalty=0)\n",
    "\n",
    "llm.invoke(\"What is the capital of the United States?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "https://python.langchain.com/docs/concepts/prompt_templates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 18, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None}, id='run-687ce73d-6187-4320-a9aa-235565782ffd-0', usage_metadata={'input_tokens': 18, 'output_tokens': 5, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a prompt template so that we can dynamically change the prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(template=\"Translate the following text to French: {input}\")\n",
    "# or prompt = PromptTemplate.from_template(\"Translate the following text to French: {input}\")\n",
    "\n",
    "chain = prompt | llm # this is a chain of the prompt and the model\n",
    "\n",
    "chain.invoke({\"input\": \"I love programming.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer that question.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# adding a system prompt. A system prompt is used to set the behavior of the model.\n",
    "# messages = [\n",
    "#     (\"system\", \"You are a helpful assistant that answers questions about the United States. If you are asked about ANYTHING that is not related to the United States, you must say 'I cannot answer that question.'\"),\n",
    "#     (\"user\", \"What is your favorite color?\"),\n",
    "# ]\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that answers questions about the United States. If you are asked about ANYTHING that is not related to the United States, you must say 'I cannot answer that question.'\"),\n",
    "    HumanMessage(content=\"What is your favorite color?\"),\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cannot answer that question.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use the ChatPromptTemplate to create a prompt and then chain it to the model so that you can dynamically change the prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessage(content=\"You are a helpful assistant that answers questions about the United States. If you are asked about ANYTHING that is not related to the United States, you must say 'I cannot answer that question.'\"),\n",
    "    HumanMessage(content=\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"input\": \"What is the capital of the United States?\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greetings, young traveler! The winds of destiny have carried your voice to the ears of Lord Jaquarious, the keeper of ancient secrets and master of arcane arts. How may I assist you on this fine day? Do you seek counsel, magical advice, or perhaps a tale of bygone eras? Speak, and I shall do my utmost to aid you.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a {occupation} named {name}. Get into character and pretend to be this role. Answer questions accordingly.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "# another way to do it\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a {occupation} named {name}. Get into character and pretend to be this role. Answer questions accordingly.\"),\n",
    "#     (\"user\", \"{input}\")\n",
    "# ])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\n",
    "    \"occupation\": \"old wizard\",\n",
    "    \"name\": \"Lord Jaquarious\",\n",
    "    \"input\": \"Hi!\"\n",
    "}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Germany is Berlin.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simplistic example of RAG to come. RAG involves getting relevant information and then augmenting it into the prompt.\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions. ONLY use the context provided to answer questions. If the context does not provide the answer, say 'I don't know.' Context: {context}\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"context\": \"The capital of Germany is Berlin.\", \"input\": \"What is the capital of the United States?\"}).content\n",
    "chain.invoke({\"context\": \"The capital of Germany is Berlin.\", \"input\": \"What is the capital of Germany?\"}).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
